# Local LLM based Chatbot

Chatbot example using **Local Models**

(Minimum of 12GB of Vram capacity NVIDIA GPU is required)



### How to make your own Local LLM via Ollama

[Creating Local LLM via Ollama](https://github.com/Juwan-s/Local_LLM_Chatbot_Service/blob/0ef24f57177abd151819fa5afbe9f8a842078450/Create_your_local_llm/README.md)

