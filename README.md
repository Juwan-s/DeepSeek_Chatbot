# Local LLM based Chatbot

Chatbot example using **Local Models**

(Minimum of 12GB of Vram capacity NVIDIA GPU is required)



### How to make your own Local LLM via Ollama

Go to https://github.com/Juwan-s/Local_LLM_Chatbot_Service.git/tree/main/Create_your_local_llm

