# Local LLM based Chatbot

Chatbot example using **Local Models**

(Minimum of 12GB of Vram capacity NVIDIA GPU is required)



### How to make your own Local LLM via Ollama

Go to 

